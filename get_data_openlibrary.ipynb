{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll proceed in two times:\n",
    "- For every isbn in our dataset, retrieve the \"work\" ID from OpenLibrary\n",
    "- For every work, retrieve the associated tags.\n",
    "\n",
    "We can't directly access the tags from the isbn.\n",
    "\n",
    "We use the time library to pause the code in order to avoid getting an error from the OpenLibrary servers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import pickle\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'data\\books.csv', on_bad_lines='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_info(isbns):\n",
    "    url = f\"https://openlibrary.org/api/books?bibkeys=ISBN:{','.join(isbns)}&format=json&jscmd=details\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "isbns = df.isbn.to_list()\n",
    "book_info_list = []\n",
    "\n",
    "for i in range(0, len(isbns), 100):\n",
    "    chunk = isbns[i:i+100]\n",
    "    book_info = get_book_info(chunk)\n",
    "    book_info_list.append(book_info)\n",
    "    if i > 0 and i % 100 == 0:\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_works(book_info_list):\n",
    "    works={}\n",
    "    for ch in book_info_list:\n",
    "        for isbn, info in ch.items():\n",
    "            isbn = isbn.replace('ISBN:','')\n",
    "            if 'details' in info and 'works' in info['details']:\n",
    "                    work_key = info['details']['works'][0]['key'].replace('/works/', '')\n",
    "                    works[isbn] = work_key\n",
    "    return works\n",
    "\n",
    "dict_isbn_works = extract_works(book_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_works = pd.DataFrame({\"isbn\":dict_isbn_works.keys(),\"work\":dict_isbn_works.values()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_works.to_csv(r\"data\\works.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn    11055\n",
       "work     9900\n",
       "dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_works.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike fetching the works ID, the API don't provide a way to request a batch of tags at once using a list of works. We have to process every single work one by one. This code took 5 hours to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(work):\n",
    "    url = f\"https://openlibrary.org//works/{work}.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "    return None\n",
    "\n",
    "works_list = list(df_works[\"work\"].unique())\n",
    "\n",
    "for i in works_list:\n",
    "    if i in tags:\n",
    "        continue\n",
    "    response = get_tags(i)\n",
    "    tags[i] = {}\n",
    "    tags[i][\"tags\"] = response.get(\"tags\") \n",
    "    tags[i][\"subject_people\"] = response.get(\"subject_people\")\n",
    "    tags[i][\"subject_times\"] = response.get(\"subject_times\")\n",
    "    tags[i][\"subject_places\"] = response.get(\"subject_places\")\n",
    "    time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the nested dictionary\n",
    "flattened_data = {k: flatten_dict(v) for k, v in tags.items()}\n",
    "\n",
    "# Create the pandas DataFrame\n",
    "df_tags = pd.DataFrame.from_dict(flattened_data, orient='index')\n",
    "\n",
    "# Reset the index and rename the columns\n",
    "df_tags.reset_index(inplace=True)\n",
    "df_tags.columns = ['work', 'subjects', 'people', 'times', 'places']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tags.to_csv(r\"data\\tags.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsti_project_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
